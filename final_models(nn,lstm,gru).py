# -*- coding: utf-8 -*-
"""Final_Models(NN,LSTM,GRU).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qdDkSU-W6JdmoAmPbWWj6EFtCjnyvar7
"""

import pandas as pd
df = pd.read_csv("merged_dataset.csv")
df

missing_values = df.isnull().sum()
missing_values

duplicate_count = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_count}")

"""# Data Preprocessing"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder
import re

# Load the dataset
data = pd.read_csv('merged_dataset.csv')

# Step 1: Remove duplicates based on the 'Text' column
data_cleaned = data.drop_duplicates()
# Step 2: Convert the 'Text' column to lowercase and remove extra white spaces using regex
def cleaned_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces and newlines
    text = re.sub(r'[^\w\s.,!?-]', '', text)  # Remove special characters
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = text.strip()  # Remove leading/trailing whitespace
    return text
data_cleaned['Text'] = data_cleaned['Text'].apply(cleaned_text)
# Step 3: Initialize LabelEncoder and encode the 'Language' column
le = LabelEncoder()
data_cleaned['Language'] = le.fit_transform(data_cleaned['Language'])

# Step 4: Saved the cleaned and encoded dataset to a new CSV file
data_cleaned.to_csv('cleaned_encoded_dataset.csv', index=False)

# Print the first few rows to inspect the result
# print(data_cleaned.head())
data_cleaned

unique_values = data_cleaned.isnull().sum()
unique_values

"""# Tokenization and Padding"""

# Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import joblib

# Load the cleaned and encoded dataset
data_cleaned = pd.read_csv('cleaned_encoded_dataset.csv')

# Extract features (X) and labels (y)
X = data_cleaned['Text']  # Text data
y = data_cleaned['Language']  # Encoded labels

# Split the data into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ensure no float values (convert to string)
X_train = X_train.astype(str)
X_test = X_test.astype(str)

# Checking for missing values
print("Missing values in X_train:", pd.Series(X_train).isnull().sum())
print("Missing values in X_test:", pd.Series(X_test).isnull().sum())

# Tokenization
vocab_size = 30000
tokenizer = Tokenizer(num_words=vocab_size)
tokenizer.fit_on_texts(X_train)

# Saved tokenizer
joblib.dump(tokenizer, 'tokenizer.joblib')

# Convert text to sequences
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Padding sequences
max_length = 100
X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')



# Printing tokenized and padded sequences
print("Tokenized Sequence (Train):", X_train_seq[:1])
print("Padded Sequence (Train):", X_train_pad[:1])
print("Tokenized Sequence (Test):", X_test_seq[:1])
print("Padded Sequence (Test):", X_test_pad[:1])

# Printing shapes to verify
print("X_train shape:", X_train_pad.shape)
print("X_test shape:", X_test_pad.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("Label Mapping:", label_mapping)

import json

# Generate the label mapping
label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("Label Mapping:", label_mapping)

# Convert all int64 to int
label_mapping = {key: int(value) for key, value in label_mapping.items()}

# Save the label mapping to a JSON file
with open('label_mapping.json', 'w') as f:
    json.dump(label_mapping, f)

print("Label mapping saved successfully!")

import joblib

# Saved the label encoder
joblib.dump(le, 'label_encoder.joblib')
print("Label Encoder saved as 'label_encoder.joblib'.")

"""# Neural Network Model"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, Dropout, Flatten

# Define the Baseline Neural Network model
num_classes = len(set(y_train))  # Number of unique classes in the dataset
model_nn = Sequential(name="My_Baseline_NN_Model",
    layers=[
        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),  # Embedding layer
        Flatten(),  # Flatten the embedding output to remove extra dimensions
        Dense(64, activation='relu'),  # Fully connected layer
        Dropout(0.5),  # Dropout to prevent overfitting
        Dense(num_classes, activation='softmax')  # Output layer
    ]
)

# Model's name and parameters summary
print(f"Model Name: {model_nn.name}")
model_nn.summary()

# Compile the model
model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training the Baseline Neural Network model
history_nn = model_nn.fit(
    X_train_pad,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_pad, y_test)
)

# Evaluation of the model
loss, accuracy = model_nn.evaluate(X_test_pad, y_test, verbose=0)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

"""# Save the NN Model"""

# Saved the entire NN model
model_nn.save('nn_model.h5')
model_nn.save('nn_model.keras')
print("NN Model saved successfully!")

"""# Performance of NN Model"""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Get predicted labels for the test data
y_pred = np.argmax(model_nn.predict(X_test_pad), axis=1)

# Generate a classification report with precision, recall, and F1-score for each language
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=list(label_mapping.keys())))

# Generate the confusion matrix to see how well the model is classifying each language
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(12, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=list(label_mapping.keys()),
            yticklabels=list(label_mapping.keys()))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# check for individual class performance
# Here, we compute precision, recall, and F1-score for each class
precision_per_class = classification_report(y_test, y_pred, target_names=list(label_mapping.keys()), output_dict=True)

for language, metrics in precision_per_class.items():
    if language not in ['accuracy', 'macro avg', 'weighted avg']:
        print(f"Language: {language}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1-score']:.4f}")
        print("-" * 30)

"""# NN Model Evaluation -- For Each Language"""

import pandas as pd
import numpy as np
import re
import joblib
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model

# Load the tokenizer, label encoder, and model
tokenizer = joblib.load('tokenizer.joblib')
encoder = joblib.load('label_encoder.joblib')
model = load_model('nn_model.keras')

def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces and newlines
    text = re.sub(r'[^\w\s.,!?-]', '', text)  # Remove special characters
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = text.strip()  # Remove leading/trailing whitespace
    return text

def preprocess_sentence(sentence, tokenizer, max_length):
    cleaned_sentence = clean_text(sentence)
    sequence = tokenizer.texts_to_sequences([cleaned_sentence])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')
    return padded_sequence

# Define all sentences
sentences = [
    "الحياة جميلة عندما نعيشها بشغف.",  # Arabic
    "生活在于追求梦想和激情。",  # Chinese
    "Livet er smukt, når vi lever det med passion.",  # Danish
    "Het leven is mooi als we het met passie leven.",  # Dutch
    "Life is beautiful when we live it with passion.",  # English
    "Elu on ilus, kui me elame seda kirega.",  # Estonian
    "La vie est belle quand on la vit avec passion.",  # French
    "Das Leben ist schön, wenn wir es mit Leidenschaft leben.",  # German
    "Η ζωή είναι όμορφη όταν τη ζούμε με πάθος.",  # Greek
    "जीवन सुंदर है जब हम इसे जुनून के साथ जीते हैं।",  # Hindi
    "Hidup itu indah ketika kita menjalani dengan penuh gairah.",  # Indonesian
    "La vita è bella quando la viviamo con passione.",  # Italian
    "人生は情熱を持って生きると美しいです。",  # Japanese
    "ಜೀವನವು ನಾವು ಅದನ್ನು ಉತ್ಸಾಹದಿಂದ ಬದುಕಿದಾಗ ಸುಂದರವಾಗಿದೆ.",  # Kannada
    "삶은 열정을 가지고 살 때 아름답습니다.",  # Korean
    "Vita pulchra est cum eam cum ardore vivimus.",  # Latin
    "ഹായ്, സുഖമാണോ",  # Malayalam
    "زندگی زمانی زیباست که آن را با اشتیاق زندگی کنیم.",  # Persian
    "A vida é bonita quando a vivemos com paixão.",  # Portuguese
    "A vida é bela quando a vivemos com paixão.",  # Portuguese (alternative spelling)
    "ژوند ښکلی دی کله چې موږ دا د جذبې سره ژوند کوو.",  # Pushto
    "Viața este frumoasă atunci când o trăim cu pasiune.",  # Romanian
    "Жизнь прекрасна, когда мы живем её с страстью.",  # Russian
    "La vida es hermosa cuando la vivimos con pasión.",  # Spanish
    "Livet är vackert när vi lever det med passion.",  # Swedish
    "Livet är vackert när vi lever det med passion.",  # Swedish (alternative spelling)
    "வாழ்க்கை அன்புடன் வாழும் போது அழகாக இருக்கும்.",  # Tamil
    "ชีวิตสวยงามเมื่อเรามีความหลงใหลในการใช้ชีวิต",  # Thai
    "Hayat, onu tutku ile yaşadığımızda güzeldir.",  # Turkish
    "زندگی خوب ہے جب ہم اسے جذبے کے ساتھ جیتے ہیں۔"  # Urdu
]

# Define actual language labels
actual_labels = [
    'Arabic', 'Chinese', 'Danish', 'Dutch', 'English', 'Estonian', 'French', 'German', 'Greek',
    'Hindi', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Latin', 'Malayalam',
    'Persian', 'Portuguese', 'Portuguese', 'Pushto', 'Romanian', 'Russian', 'Spanish', 'Swedish',
    'Swedish', 'Tamil', 'Thai', 'Turkish', 'Urdu'
]

# Iterate over all sentences
for i, sentence in enumerate(sentences):
    # Preprocess and predict
    input_data = preprocess_sentence(sentence, tokenizer, max_length=100)
    input_data = np.reshape(input_data, (1, 100))  # Ensure batch size of 1

    prediction = model.predict(input_data)
    predicted_class_index = np.argmax(prediction)  # Get the index of the highest probability
    predicted_class_label = encoder.inverse_transform([predicted_class_index])[0]  # Map index to original label

    # Output results
    print(f"Input Sentence: {sentence}")
    print(f"Actual Language: {actual_labels[i]}")
    print(f"Predicted Class Index: {predicted_class_index}")
    print(f"Predicted Class Label: {predicted_class_label}")
    print("="*50)

"""#  Long Short-Term Memory(LSTM) Model"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Flatten

# Define the LSTM Neural Network model
num_classes = len(set(y_train))  # Number of unique classes in the dataset
model_lstm = Sequential(name="My_LSTM_Model",
    layers=[
        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),  # Embedding layer
        LSTM(128, return_sequences=False),  # LSTM layer
        Dropout(0.5),  # Dropout to prevent overfitting
        Dense(64, activation='relu'),  # Fully connected layer
        Dense(num_classes, activation='softmax')  # Output layer
    ]
)

# Model's name and parameters summary
print(f"Model Name: {model_lstm.name}")
model_lstm.summary()

# Compile the model
model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training the LSTM model
history_lstm = model_lstm.fit(
    X_train_pad,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_pad, y_test)
)

# Evaluation of the model
loss, accuracy = model_lstm.evaluate(X_test_pad, y_test, verbose=0)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

"""# Save the LSTM Model"""

model.save('LSTM_Model.h5')
model.save('LSTM_Model.keras')
print("LSTM Model saved Successfully!")

"""# Performance of LSTM Model"""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Language labels updated based on the label mapping
top_preds_labels = [[list(label_mapping.keys())[list(label_mapping.values()).index(i)] for i in row] for row in top_preds]
Language_labels = list(label_mapping.keys())

# Get predicted labels for the test data
y_pred = np.argmax(model_lstm.predict(X_test_pad), axis=1)

# Generate a classification report with precision, recall, and F1-score for each language
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=Language_labels))

# Generate the confusion matrix to see how well the model is classifying each language
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(12, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=Language_labels,
            yticklabels=Language_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Check for individual class performance
# Here, we compute precision, recall, and F1-score for each class
precision_per_class = classification_report(y_test, y_pred, target_names=Language_labels, output_dict=True)

# Display precision, recall, and F1-score for each language
for language, metrics in precision_per_class.items():
    if language not in ['accuracy', 'macro avg', 'weighted avg']:
        print(f"Language: {language}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1-score']:.4f}")
        print("-" * 30)

"""# LSTM Model Evaluation - For each Language"""

import pandas as pd
import numpy as np
import re
import joblib
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model

# Load the tokenizer, label encoder, and model
tokenizer = joblib.load('tokenizer.joblib')
encoder = joblib.load('label_encoder.joblib')
model = load_model('LSTM_Model.keras')  # LSTM model

def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces and newlines
    text = re.sub(r'[^\w\s.,!?-]', '', text)  # Remove special characters
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = text.strip()  # Remove leading/trailing whitespace
    return text

def preprocess_sentence(sentence, tokenizer, max_length):
    cleaned_sentence = clean_text(sentence)
    sequence = tokenizer.texts_to_sequences([cleaned_sentence])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')
    # Reshape the padded sequence to 3D array for LSTM: (batch_size, sequence_length, num_features)
    padded_sequence = np.reshape(padded_sequence, (padded_sequence.shape[0], padded_sequence.shape[1], 1))
    return padded_sequence

# Define all sentences
sentences = [
    "الحياة جميلة عندما نعيشها بشغف.",  # Arabic
    "生活在于追求梦想和激情。",  # Chinese
    "Livet er smukt, når vi lever det med passion.",  # Danish
    "Het leven is mooi als we het met passie leven.",  # Dutch
    "Life is beautiful when we live it with passion.",  # English
    "Elu on ilus, kui me elame seda kirega.",  # Estonian
    "La vie est belle quand on la vit avec passion.",  # French
    "Das Leben ist schön, wenn wir es mit Leidenschaft leben.",  # German
    "Η ζωή είναι όμορφη όταν τη ζούμε με πάθος.",  # Greek
    "जीवन सुंदर है जब हम इसे जुनून के साथ जीते हैं।",  # Hindi
    "Hidup itu indah ketika kita menjalani dengan penuh gairah.",  # Indonesian
    "La vita è bella quando la viviamo con passione.",  # Italian
    "人生は情熱を持って生きると美しいです。",  # Japanese
    "ಜೀವನವು ನಾವು ಅದನ್ನು ಉತ್ಸಾಹದಿಂದ ಬದುಕಿದಾಗ ಸುಂದರವಾಗಿದೆ.",  # Kannada
    "삶은 열정을 가지고 살 때 아름답습니다.",  # Korean
    "Vita pulchra est cum eam cum ardore vivimus.",  # Latin
    "ഹായ്, സുഖമാണോ",  # Malayalam
    "زندگی زمانی زیباست که آن را با اشتیاق زندگی کنیم.",  # Persian
    "A vida é bonita quando a vivemos com paixão.",  # Portuguese
    "A vida é bela quando a vivemos com paixão.",  # Portuguese (alternative spelling)
    "ژوند ښکلی دی کله چې موږ دا د جذبې سره ژوند کوو.",  # Pushto
    "Viața este frumoasă atunci când o trăim cu pasiune.",  # Romanian
    "Жизнь прекрасна, когда мы живем её с страстью.",  # Russian
    "La vida es hermosa cuando la vivimos con pasión.",  # Spanish
    "Livet är vackert när vi lever det med passion.",  # Swedish
    "Livet är vackert när vi lever det med passion.",  # Swedish (alternative spelling)
    "வாழ்க்கை அன்புடன் வாழும் போது அழகாக இருக்கும்.",  # Tamil
    "ชีวิตสวยงามเมื่อเรามีความหลงใหลในการใช้ชีวิต",  # Thai
    "Hayat, onu tutku ile yaşadığımızda güzeldir.",  # Turkish
    "زندگی خوب ہے جب ہم اسے جذبے کے ساتھ جیتے ہیں۔"  # Urdu
]

# Define actual language labels
actual_labels = [
    'Arabic', 'Chinese', 'Danish', 'Dutch', 'English', 'Estonian', 'French', 'German', 'Greek',
    'Hindi', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Latin', 'Malayalam',
    'Persian', 'Portuguese', 'Portuguese', 'Pushto', 'Romanian', 'Russian', 'Spanish', 'Swedish',
    'Swedish', 'Tamil', 'Thai', 'Turkish', 'Urdu'
]

# Iterate over all sentences
for i, sentence in enumerate(sentences):
    # Preprocess and predict
    input_data = preprocess_sentence(sentence, tokenizer, max_length=100)  # Adjust max_length as needed
    input_data = np.reshape(input_data, (1, input_data.shape[1], 1))  # Ensure batch size of 1 and shape for LSTM

    prediction = model.predict(input_data)
    predicted_class_index = np.argmax(prediction)  # Get the index of the highest probability
    predicted_class_label = encoder.inverse_transform([predicted_class_index])[0]  # Map index to original label

    # Output results
    print(f"Input Sentence: {sentence}")
    print(f"Actual Language: {actual_labels[i]}")
    print(f"Predicted Class Index: {predicted_class_index}")
    print(f"Predicted Class Label: {predicted_class_label}")
    print("="*50)

"""# Gated Recurrent Unit(GRU) Model"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, Dropout, GRU, Flatten

# Define the GRU model
num_classes = len(set(y_train))  # Number of unique classes in the dataset
model_gru = Sequential(name="My_GRU_Model",
    layers=[
        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),  # Embedding layer
        GRU(128, return_sequences=False),  # GRU layer with 128 units
        Dropout(0.5),  # Dropout to prevent overfitting
        Dense(64, activation='relu'),  # Fully connected layer
        Dense(num_classes, activation='softmax')  # Output layer
    ]
)

# Model's name and parameters summary
print(f"Model Name: {model_gru.name}")
model_gru.summary()

# Compile the model
model_gru.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training the GRU model
history_gru = model_gru.fit(
    X_train_pad,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_pad, y_test)
)

# Evaluation of the model
loss, accuracy = model_gru.evaluate(X_test_pad, y_test, verbose=0)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

"""# Save GRU Model"""

model.save('GRU_Model.h5')
model.save('GRU_Model.keras')
print("GRU Model saved successfully!")

"""# Performance of GRU Model"""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Get predicted labels for the test data using the GRU model
y_pred_gru = np.argmax(model_gru.predict(X_test_pad), axis=1)

# Generate a classification report with precision, recall, and F1-score for each language
print("Classification Report - GRU Model:\n",
      classification_report(y_test, y_pred_gru, target_names=Language_labels))

# Generate the confusion matrix to analyze classification performance
cm_gru = confusion_matrix(y_test, y_pred_gru)

# Plot the confusion matrix for the GRU model
plt.figure(figsize=(12, 8))
sns.heatmap(cm_gru, annot=True, fmt='d', cmap='Blues',
            xticklabels=Language_labels,
            yticklabels=Language_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - GRU Model')
plt.show()

# Evaluate individual class performance
precision_per_class_gru = classification_report(
    y_test, y_pred_gru, target_names=Language_labels, output_dict=True
)

# Display precision, recall, and F1-score for each language
for language, metrics in precision_per_class_gru.items():
    if language not in ['accuracy', 'macro avg', 'weighted avg']:
        print(f"Language: {language}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1-score']:.4f}")
        print("-" * 30)

"""# GRU Model Evaluation - For each Language"""

import pandas as pd
import numpy as np
import re
import joblib
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model

# Load the tokenizer, label encoder, and GRU model
tokenizer = joblib.load('tokenizer.joblib')
encoder = joblib.load('label_encoder.joblib')
model = load_model('GRU_Model.keras')  # Load the GRU model

# Text cleaning function
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces and newlines
    text = re.sub(r'[^\w\s.,!?-]', '', text)  # Remove special characters
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = text.strip()  # Remove leading/trailing whitespace
    return text

# Preprocessing function
def preprocess_sentence(sentence, tokenizer, max_length):
    cleaned_sentence = clean_text(sentence)
    sequence = tokenizer.texts_to_sequences([cleaned_sentence])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')
    return padded_sequence

# Sentences and labels
sentences = [
    "الحياة جميلة عندما نعيشها بشغف.",  # Arabic
    "生活在于追求梦想和激情。",  # Chinese
    "Livet er smukt, når vi lever det med passion.",  # Danish
    "Het leven is mooi als we het met passie leven.",  # Dutch
    "Life is beautiful when we live it with passion.",  # English
    "Elu on ilus, kui me elame seda kirega.",  # Estonian
    "La vie est belle quand on la vit avec passion.",  # French
    "Das Leben ist schön, wenn wir es mit Leidenschaft leben.",  # German
    "Η ζωή είναι όμορφη όταν τη ζούμε με πάθος.",  # Greek
    "जीवन सुंदर है जब हम इसे जुनून के साथ जीते हैं।",  # Hindi
    "Hidup itu indah ketika kita menjalani dengan penuh gairah.",  # Indonesian
    "La vita è bella quando la viviamo con passione.",  # Italian
    "人生は情熱を持って生きると美しいです。",  # Japanese
    "ಜೀವನವು ನಾವು ಅದನ್ನು ಉತ್ಸಾಹದಿಂದ ಬದುಕಿದಾಗ ಸುಂದರವಾಗಿದೆ.",  # Kannada
    "삶은 열정을 가지고 살 때 아름답습니다.",  # Korean
    "Vita pulchra est cum eam cum ardore vivimus.",  # Latin
    "ഹായ്, സുഖമാണോ",  # Malayalam
    "زندگی زمانی زیباست که آن را با اشتیاق زندگی کنیم.",  # Persian
    "A vida é bonita quando a vivemos com paixão.",  # Portuguese
    "A vida é bela quando a vivemos com paixão.",  # Portuguese (alternative)
    "ژوند ښکلی دی کله چې موږ دا د جذبې سره ژوند کوو.",  # Pushto
    "Viața este frumoasă atunci când o trăim cu pasiune.",  # Romanian
    "Жизнь прекрасна, когда мы живем её с страстью.",  # Russian
    "La vida es hermosa cuando la vivimos con pasión.",  # Spanish
    "Livet är vackert när vi lever det med passion.",  # Swedish
    "Livet är vackert när vi lever det med passion.",  # Swedish (alternative)
    "வாழ்க்கை அன்புடன் வாழும் போது அழகாக இருக்கும்.",  # Tamil
    "ชีวิตสวยงามเมื่อเรามีความหลงใหลในการใช้ชีวิต",  # Thai
    "Hayat, onu tutku ile yaşadığımızda güzeldir.",  # Turkish
    "زندگی خوب ہے جب ہم اسے جذبے کے ساتھ جیتے ہیں۔"  # Urdu
]

actual_labels = [
    'Arabic', 'Chinese', 'Danish', 'Dutch', 'English', 'Estonian', 'French', 'German', 'Greek',
    'Hindi', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Latin', 'Malayalam',
    'Persian', 'Portuguese', 'Portuguese', 'Pushto', 'Romanian', 'Russian', 'Spanish', 'Swedish',
    'Swedish', 'Tamil', 'Thai', 'Turkish', 'Urdu'
]

# Model predictions
for i, sentence in enumerate(sentences):
    input_data = preprocess_sentence(sentence, tokenizer, max_length=100)
    input_data = np.reshape(input_data, (1, 100))

    prediction = model.predict(input_data)
    predicted_class_index = np.argmax(prediction)
    predicted_class_label = encoder.inverse_transform([predicted_class_index])[0]

    print(f"Input Sentence: {sentence}")
    print(f"Actual Language: {actual_labels[i]}")
    print(f"Predicted Class Index: {predicted_class_index}")
    print(f"Predicted Class Label: {predicted_class_label}")
    print("="*50)

"""# Comparision of Performances of NN , LSTM , GRU"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import accuracy_score

# Plot Training and Validation Accuracy and Loss
def plot_training_history(history, model_name):
    plt.figure(figsize=(12, 6))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title(f'{model_name} Accuracy')
    plt.legend()

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title(f'{model_name} Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Evaluate Model Performance
def evaluate_model(model, X_test, y_test):
    # Evaluate the model
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    return accuracy, loss

# Confidence Distribution
def plot_confidence_distribution(model, title, X_test):
    y_pred_proba = model.predict(X_test)
    confidences = np.max(y_pred_proba, axis=1)
    plt.figure(figsize=(8, 6))
    plt.hist(confidences, bins=20, color='skyblue', edgecolor='black')
    plt.title(f'{title} Prediction Confidence Distribution')
    plt.xlabel('Confidence')
    plt.ylabel('Frequency')
    plt.show()

# Example Usage for Models
metrics = {}

# Neural Network
plot_training_history(history_nn, 'Neural Network')
accuracy_nn, loss_nn = evaluate_model(model_nn, X_test_pad, y_test)
plot_confidence_distribution(model_nn, 'Neural Network', X_test_pad)
metrics['Neural Network'] = {'accuracy': accuracy_nn, 'loss': loss_nn}

# LSTM
plot_training_history(history_lstm, 'LSTM')
accuracy_lstm, loss_lstm = evaluate_model(model_lstm, X_test_pad, y_test)
plot_confidence_distribution(model_lstm, 'LSTM', X_test_pad)
metrics['LSTM'] = {'accuracy': accuracy_lstm, 'loss': loss_lstm}

# GRU
plot_training_history(history_gru, 'GRU')
accuracy_gru, loss_gru = evaluate_model(model_gru, X_test_pad, y_test)
plot_confidence_distribution(model_gru, 'GRU', X_test_pad)
metrics['GRU'] = {'accuracy': accuracy_gru, 'loss': loss_gru}

# Summary Table
print("\nSummary Table:")
print("| Model | Accuracy | Loss |")
print("|-------|----------|------|")
for name, metric in metrics.items():
    print(f"| {name} | {metric['accuracy']:.4f} | {metric['loss']:.4f} |")