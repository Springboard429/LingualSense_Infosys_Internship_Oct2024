{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10333</th>\n",
       "      <td>ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10334</th>\n",
       "      <td>ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10335</th>\n",
       "      <td>ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336</th>\n",
       "      <td>ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...</td>\n",
       "      <td>Kannada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Language\n",
       "0       Nature, in the broadest sense, is the natural...  English\n",
       "1      \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2      The study of nature is a large, if not the onl...  English\n",
       "3      Although humans are part of nature, human acti...  English\n",
       "4      [1] The word nature is borrowed from the Old F...  English\n",
       "...                                                  ...      ...\n",
       "10332  ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...  Kannada\n",
       "10333  ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...  Kannada\n",
       "10334  ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...  Kannada\n",
       "10335  ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...  Kannada\n",
       "10336  ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...  Kannada\n",
       "\n",
       "[10337 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..\\Language Detection.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_multilingual_text(text):\n",
    "    text = re.sub(r'[^\\w\\s\\u0900-\\u097F\\u0D00-\\u0D7F\\u0B80-\\u0BFF\\u0600-\\u06FF]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['Text'].apply(preprocess_multilingual_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text for GRU model\n",
    "max_vocab_size = 10000\n",
    "max_length = 200\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['cleaned_text'])\n",
    "X_padded = pad_sequences(sequences, maxlen=200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n",
      "WARNING:tensorflow:From c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "259/259 [==============================] - 46s 165ms/step - loss: 2.5313 - accuracy: 0.1469 - val_loss: 2.2737 - val_accuracy: 0.2099 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "259/259 [==============================] - 42s 163ms/step - loss: 2.0743 - accuracy: 0.2648 - val_loss: 1.6606 - val_accuracy: 0.4038 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "259/259 [==============================] - 43s 167ms/step - loss: 1.2573 - accuracy: 0.5278 - val_loss: 1.0555 - val_accuracy: 0.6165 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "259/259 [==============================] - 57s 221ms/step - loss: 0.8574 - accuracy: 0.6903 - val_loss: 0.7501 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "259/259 [==============================] - 47s 183ms/step - loss: 0.5882 - accuracy: 0.7956 - val_loss: 0.4688 - val_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 0.4353 - accuracy: 0.8540 - val_loss: 0.3718 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "259/259 [==============================] - 63s 244ms/step - loss: 0.3345 - accuracy: 0.8846 - val_loss: 0.3369 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "259/259 [==============================] - 63s 244ms/step - loss: 0.2889 - accuracy: 0.8989 - val_loss: 0.2979 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "259/259 [==============================] - 56s 216ms/step - loss: 0.2503 - accuracy: 0.9117 - val_loss: 0.2749 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 0.2100 - accuracy: 0.9284 - val_loss: 0.2377 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "259/259 [==============================] - 65s 252ms/step - loss: 0.1855 - accuracy: 0.9342 - val_loss: 0.2149 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "259/259 [==============================] - 64s 248ms/step - loss: 0.1739 - accuracy: 0.9400 - val_loss: 0.2093 - val_accuracy: 0.9328 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "259/259 [==============================] - 63s 245ms/step - loss: 0.1475 - accuracy: 0.9469 - val_loss: 0.2022 - val_accuracy: 0.9357 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "259/259 [==============================] - 55s 213ms/step - loss: 0.1304 - accuracy: 0.9553 - val_loss: 0.2011 - val_accuracy: 0.9381 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "259/259 [==============================] - 53s 203ms/step - loss: 0.1067 - accuracy: 0.9628 - val_loss: 0.1748 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "259/259 [==============================] - 54s 208ms/step - loss: 0.0978 - accuracy: 0.9670 - val_loss: 0.1812 - val_accuracy: 0.9468 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "259/259 [==============================] - 64s 248ms/step - loss: 0.0835 - accuracy: 0.9710 - val_loss: 0.2105 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "259/259 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9719\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "259/259 [==============================] - 63s 243ms/step - loss: 0.0795 - accuracy: 0.9719 - val_loss: 0.2148 - val_accuracy: 0.9420 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "259/259 [==============================] - 56s 216ms/step - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.2059 - val_accuracy: 0.9454 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 0.0478 - accuracy: 0.9820 - val_loss: 0.1952 - val_accuracy: 0.9492 - lr: 5.0000e-04\n",
      "65/65 [==============================] - 6s 86ms/step - loss: 0.1748 - accuracy: 0.9463\n",
      "GRU Test Accuracy: 94.63%\n",
      "MLP Test Accuracy: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ensure GPU usage\n",
    "print(\"Training on GPU\" if tf.config.list_physical_devices('GPU') else \"Training on CPU\")\n",
    "\n",
    "# Encode the target labels\n",
    "y = df['Language'].factorize()[0]  # Label encode\n",
    "\n",
    "# Split data for GRU\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build GRU Model\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=max_vocab_size, output_dim=256, input_length=max_length),\n",
    "    Bidirectional(GRU(128, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    GRU(128),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile GRU model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "gru_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# Train GRU model\n",
    "gru_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32,\n",
    "              callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate GRU model\n",
    "gru_loss, gru_accuracy = gru_model.evaluate(X_test, y_test)\n",
    "print(f\"GRU Test Accuracy: {gru_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Train and Save MLP Model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
    "\n",
    "# Split data for MLP\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train MLP model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', alpha=0.001,\n",
    "                          learning_rate='adaptive', max_iter=50, random_state=42)\n",
    "mlp_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate MLP model\n",
    "mlp_preds = mlp_model.predict(X_test_tfidf)\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_preds)\n",
    "print(f\"MLP Test Accuracy: {mlp_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 6s 80ms/step\n",
      "Ensemble Test Accuracy: 98.45%\n"
     ]
    }
   ],
   "source": [
    "# GRU Predictions (probabilities)\n",
    "gru_preds = gru_model.predict(X_test)\n",
    "\n",
    "# MLP Predictions (probabilities)\n",
    "mlp_preds_proba = mlp_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Ensemble by averaging predictions\n",
    "final_preds = (0.5 * gru_preds) + (0.5 * mlp_preds_proba)\n",
    "final_preds = np.argmax(final_preds, axis=1)\n",
    "\n",
    "# Evaluate Ensemble Model\n",
    "ensemble_accuracy = accuracy_score(y_test, final_preds)\n",
    "print(f\"Ensemble Test Accuracy: {ensemble_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU and MLP models saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hariesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save GRU model\n",
    "gru_model.save('gru_language_model_2.h5')\n",
    "\n",
    "# Save MLP model\n",
    "joblib.dump(mlp_model, 'mlp_language_model_2.pkl')\n",
    "\n",
    "print(\"GRU and MLP models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
